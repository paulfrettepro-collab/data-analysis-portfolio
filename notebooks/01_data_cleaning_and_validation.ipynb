{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e562bad",
   "metadata": {},
   "source": [
    "# ğŸ“Š Data Cleaning & Validation - Portfolio Project\n",
    "\n",
    "**Auteur**: Paul Frette  \n",
    "**Objectif**: DÃ©monstration de techniques de nettoyage et validation de donnÃ©es  \n",
    "**Technologies**: Python, Pandas, NumPy, Regex\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Contexte\n",
    "\n",
    "Ce notebook dÃ©montre mes compÃ©tences en nettoyage et validation de donnÃ©es sur un cas d'usage rÃ©el :\n",
    "- Import et nettoyage de donnÃ©es clients provenant de sources multiples\n",
    "- Standardisation des formats\n",
    "- Validation des emails et tÃ©lÃ©phones avec regex\n",
    "- Analyse de qualitÃ© des donnÃ©es\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78473d5",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Import des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… Librairies importÃ©es avec succÃ¨s\")\n",
    "print(f\"ğŸ“¦ Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“¦ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2df988",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ CrÃ©ation de DonnÃ©es de DÃ©monstration\n",
    "\n",
    "Pour ce portfolio, je crÃ©e un jeu de donnÃ©es fictif reprÃ©sentatif du type de donnÃ©es que j'ai traitÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©ation d'un dataset fictif pour dÃ©monstration\n",
    "np.random.seed(42)\n",
    "\n",
    "data = {\n",
    "    'ID': range(1, 101),\n",
    "    'First Name': ['John', 'Jane', 'Bob', 'Alice', 'Charlie'] * 20,\n",
    "    'Last Name': ['Doe', 'Smith', 'Johnson', 'Williams', 'Brown'] * 20,\n",
    "    'Email': [\n",
    "        'john.doe@email.com', 'jane.smith@company.fr', 'bob@invalid',\n",
    "        'alice.williams@test.com', 'charlie.brown@example.org'\n",
    "    ] * 20,\n",
    "    'Phone': [\n",
    "        '0612345678', '06-12-34-56-78', '0612345', \n",
    "        '0612345678', 'invalid_phone'\n",
    "    ] * 20,\n",
    "    'Mobile Phone': [None, '0698765432', None, '0698765432', None] * 20,\n",
    "    'Phone1': ['0612345678', None, None, None, '0687654321'] * 20,\n",
    "    'Gender': ['Male', 'Female', 'male', 'FEMALE', None] * 20,\n",
    "    'Created At': pd.date_range('2022-01-01', periods=100, freq='D'),\n",
    "    'Type Contact': ['individual', 'company', 'Individual', 'Company', None] * 20\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"âœ… Dataset crÃ©Ã©: {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e1c10",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Nettoyage des Noms de Colonnes\n",
    "\n",
    "**ProblÃ¨me**: Les colonnes ont des espaces et des majuscules incohÃ©rentes.  \n",
    "**Solution**: Standardisation avec regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f6af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(column_name):\n",
    "    \"\"\"\n",
    "    Nettoie les noms de colonnes:\n",
    "    - Remplace caractÃ¨res spÃ©ciaux par underscores\n",
    "    - Convertit en minuscules\n",
    "    \"\"\"\n",
    "    cleaned_name = re.sub(r\"[^a-zA-Z0-9]\", \"_\", column_name)\n",
    "    cleaned_name = cleaned_name.lower()\n",
    "    return cleaned_name\n",
    "\n",
    "# Appliquer sur toutes les colonnes\n",
    "print(\"ğŸ“ Colonnes avant nettoyage:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "new_column_names = {old: clean_column_name(old) for old in df.columns}\n",
    "df = df.rename(columns=new_column_names)\n",
    "\n",
    "print(\"\\nâœ… Colonnes aprÃ¨s nettoyage:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b4914",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ SÃ©lection du TÃ©lÃ©phone Principal\n",
    "\n",
    "**ProblÃ¨me**: Plusieurs colonnes de tÃ©lÃ©phone, besoin de sÃ©lectionner la plus fiable.  \n",
    "**Solution**: Fonction avec logique de prioritÃ© et validation regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_probable_phone(row):\n",
    "    \"\"\"\n",
    "    Parcourt les colonnes de tÃ©lÃ©phone par ordre de prioritÃ©\n",
    "    et retourne le premier numÃ©ro valide (10 chiffres).\n",
    "    \"\"\"\n",
    "    phone_columns = ['phone', 'mobile_phone', 'phone1']\n",
    "    \n",
    "    for column in phone_columns:\n",
    "        if column in row.index and isinstance(row[column], str):\n",
    "            # VÃ©rification: au moins 10 chiffres consÃ©cutifs\n",
    "            if re.search(r'\\d{10}', row[column]):\n",
    "                return row[column]\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction\n",
    "df['phone_principal'] = df.apply(get_most_probable_phone, axis=1)\n",
    "\n",
    "print(\"âœ… TÃ©lÃ©phone principal extrait\")\n",
    "print(f\"Taux de complÃ©tude: {df['phone_principal'].notna().sum() / len(df) * 100:.1f}%\")\n",
    "df[['phone', 'mobile_phone', 'phone1', 'phone_principal']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e8d96",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Conversion de Types avec Gestion d'Erreurs\n",
    "\n",
    "**Objectif**: Convertir les colonnes vers les types appropriÃ©s sans plantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion sÃ©curisÃ©e des types\n",
    "print(\"ğŸ“Š Types avant conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Entiers nullables (accepte les NaN)\n",
    "df['id'] = pd.to_numeric(df['id'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Dates\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# CatÃ©gories (Ã©conomie de mÃ©moire)\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "df['type_contact'] = df['type_contact'].astype('category')\n",
    "\n",
    "# Strings\n",
    "string_columns = ['first_name', 'last_name', 'email', 'phone_principal']\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "print(\"\\nâœ… Types aprÃ¨s conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nğŸ’¾ RÃ©duction mÃ©moire avec catÃ©gories: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b831bd1",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Validation d'Emails avec Regex\n",
    "\n",
    "**Objectif**: Identifier les emails valides/invalides pour nettoyage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_email(email):\n",
    "    \"\"\"\n",
    "    Valide un email avec regex selon le format standard.\n",
    "    \"\"\"\n",
    "    if not isinstance(email, str) or email == 'nan':\n",
    "        return False\n",
    "    \n",
    "    regex = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "    return bool(re.match(regex, email))\n",
    "\n",
    "# Appliquer la validation\n",
    "df['email_valid'] = df['email'].apply(is_valid_email)\n",
    "\n",
    "# Statistiques\n",
    "valid_count = df['email_valid'].sum()\n",
    "invalid_count = (~df['email_valid']).sum()\n",
    "\n",
    "print(f\"âœ… Emails valides: {valid_count} ({valid_count/len(df)*100:.1f}%)\")\n",
    "print(f\"âŒ Emails invalides: {invalid_count} ({invalid_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Exemples d'emails invalides\n",
    "print(\"\\nğŸ“§ Exemples d'emails invalides:\")\n",
    "print(df[~df['email_valid']][['email']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9089c",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Validation de NumÃ©ros de TÃ©lÃ©phone\n",
    "\n",
    "**Format attendu**: 10 chiffres (format franÃ§ais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_phone(phone):\n",
    "    \"\"\"\n",
    "    Valide un numÃ©ro de tÃ©lÃ©phone (10 chiffres).\n",
    "    \"\"\"\n",
    "    if not isinstance(phone, str) or phone == 'None':\n",
    "        return False\n",
    "    \n",
    "    # Extraire uniquement les chiffres\n",
    "    digits = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # VÃ©rifier 10 chiffres exactement\n",
    "    return len(digits) == 10\n",
    "\n",
    "# Validation\n",
    "df['phone_valid'] = df['phone_principal'].apply(is_valid_phone)\n",
    "\n",
    "valid_phones = df['phone_valid'].sum()\n",
    "invalid_phones = (~df['phone_valid']).sum()\n",
    "\n",
    "print(f\"âœ… TÃ©lÃ©phones valides: {valid_phones} ({valid_phones/len(df)*100:.1f}%)\")\n",
    "print(f\"âŒ TÃ©lÃ©phones invalides: {invalid_phones} ({invalid_phones/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Exemples invalides\n",
    "print(\"\\nğŸ“ Exemples de tÃ©lÃ©phones invalides:\")\n",
    "print(df[~df['phone_valid']][['phone_principal']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f385f6",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Analyse de ComplÃ©tude des DonnÃ©es\n",
    "\n",
    "**Objectif**: Mesurer la qualitÃ© du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le taux de complÃ©tude\n",
    "completeness = df.notna().sum() / len(df)\n",
    "\n",
    "# CrÃ©er un rapport dÃ©taillÃ©\n",
    "quality_report = pd.DataFrame({\n",
    "    'Colonne': df.columns,\n",
    "    'Type': df.dtypes,\n",
    "    'Valeurs Non-Nulles': df.notna().sum(),\n",
    "    'Valeurs Nulles': df.isnull().sum(),\n",
    "    'Taux ComplÃ©tude (%)': (completeness * 100).round(2)\n",
    "})\n",
    "\n",
    "quality_report = quality_report.sort_values('Taux ComplÃ©tude (%)', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š Rapport de QualitÃ© des DonnÃ©es\")\n",
    "print(\"=\" * 70)\n",
    "print(quality_report.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e1a97",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Visualisation de la QualitÃ©\n",
    "\n",
    "Graphique visuel du taux de complÃ©tude par colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique de complÃ©tude\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# PrÃ©parer les donnÃ©es pour le graphique\n",
    "plot_data = quality_report[['Colonne', 'Taux ComplÃ©tude (%)']].head(10)\n",
    "\n",
    "plt.barh(plot_data['Colonne'], plot_data['Taux ComplÃ©tude (%)'], \n",
    "         color='steelblue', edgecolor='navy')\n",
    "plt.xlabel('Taux de ComplÃ©tude (%)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Colonnes', fontsize=12, fontweight='bold')\n",
    "plt.title('Taux de ComplÃ©tude par Colonne', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 105)\n",
    "\n",
    "# Ajouter une ligne de rÃ©fÃ©rence Ã  95%\n",
    "plt.axvline(x=95, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Seuil 95%')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualisation gÃ©nÃ©rÃ©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433c4d2",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ DÃ©tection de Doublons\n",
    "\n",
    "Identifier les doublons sur emails et tÃ©lÃ©phones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d66ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons sur email\n",
    "email_duplicates = df[df['email_valid']]['email'].duplicated(keep=False).sum()\n",
    "print(f\"ğŸ“§ Doublons d'emails: {email_duplicates} ({email_duplicates/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Doublons sur tÃ©lÃ©phone\n",
    "phone_duplicates = df[df['phone_valid']]['phone_principal'].duplicated(keep=False).sum()\n",
    "print(f\"ğŸ“ Doublons de tÃ©lÃ©phones: {phone_duplicates} ({phone_duplicates/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Afficher des exemples de doublons\n",
    "if email_duplicates > 0:\n",
    "    print(\"\\nğŸ“‹ Exemples de doublons d'emails:\")\n",
    "    duplicate_emails = df[df['email'].duplicated(keep=False)].sort_values('email')\n",
    "    print(duplicate_emails[['id', 'first_name', 'last_name', 'email']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74514757",
   "metadata": {},
   "source": [
    "## ğŸ“Š RÃ©sumÃ© Final\n",
    "\n",
    "Rapport consolidÃ© de l'analyse de qualitÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7af387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š RÃ‰SUMÃ‰ DE L'ANALYSE DE QUALITÃ‰ DES DONNÃ‰ES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ“ˆ Dataset: {df.shape[0]} lignes Ã— {df.shape[1]} colonnes\")\n",
    "print(f\"\\nâœ… Emails valides: {df['email_valid'].sum()} / {len(df)} ({df['email_valid'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"âœ… TÃ©lÃ©phones valides: {df['phone_valid'].sum()} / {len(df)} ({df['phone_valid'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nğŸ”„ Doublons emails: {email_duplicates}\")\n",
    "print(f\"ğŸ”„ Doublons tÃ©lÃ©phones: {phone_duplicates}\")\n",
    "print(f\"\\nğŸ’¾ Utilisation mÃ©moire: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ¨ Analyse terminÃ©e avec succÃ¨s !\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6894dba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ CompÃ©tences DÃ©montrÃ©es\n",
    "\n",
    "âœ… **Nettoyage de donnÃ©es**\n",
    "- Standardisation des noms de colonnes avec regex\n",
    "- SÃ©lection intelligente de donnÃ©es multiples sources\n",
    "\n",
    "âœ… **Validation de donnÃ©es**\n",
    "- Regex pour emails (format standard)\n",
    "- Regex pour tÃ©lÃ©phones (format franÃ§ais)\n",
    "\n",
    "âœ… **Conversion de types**\n",
    "- Gestion d'erreurs avec `errors='coerce'`\n",
    "- Types nullables (`Int64`)\n",
    "- Optimisation mÃ©moire (catÃ©gories)\n",
    "\n",
    "âœ… **Analyse de qualitÃ©**\n",
    "- Taux de complÃ©tude\n",
    "- DÃ©tection de doublons\n",
    "- Visualisations claires\n",
    "\n",
    "âœ… **Bonnes pratiques**\n",
    "- Code commentÃ© et documentÃ©\n",
    "- Fonctions rÃ©utilisables\n",
    "- Rapports structurÃ©s\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Paul Frette  \n",
    "**Contact**: paul.frette.pro@gmail.com  \n",
    "**GitHub**: https://github.com/paulfrettepro-collab/data-analysis-portfolio"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
